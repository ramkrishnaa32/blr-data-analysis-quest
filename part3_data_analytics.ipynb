{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Data Analytics with PySpark"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T08:16:10.908801Z",
     "start_time": "2025-09-03T08:16:10.862108Z"
    }
   },
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import boto3\n",
    "import json\n",
    "from io import StringIO\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T08:16:23.618362Z",
     "start_time": "2025-09-03T08:16:23.521275Z"
    }
   },
   "source": [
    "# Initialize Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"RearcDataAnalytics\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Configuration\n",
    "BUCKET_NAME = 'rearc-data-quest-us-east-01'\n",
    "s3_client = boto3.client('s3')"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T08:16:34.207022Z",
     "start_time": "2025-09-03T08:16:28.073792Z"
    }
   },
   "source": [
    "# Load BLS data\n",
    "obj = s3_client.get_object(Bucket=BUCKET_NAME, Key='bls-data/pub/time.series/pr/pr.data.0.Current')\n",
    "csv_content = obj['Body'].read().decode('utf-8')\n",
    "\n",
    "# Create DataFrame from CSV content\n",
    "from pyspark.sql import Row\n",
    "import csv\n",
    "\n",
    "lines = csv_content.strip().split('\\n')\n",
    "reader = csv.DictReader(StringIO(csv_content), delimiter='\\t')\n",
    "rows = [Row(**{k.strip(): v.strip() if v else None for k, v in row.items()}) for row in reader]\n",
    "\n",
    "bls_df = spark.createDataFrame(rows)\n",
    "bls_df = bls_df.withColumn(\"year\", col(\"year\").cast(IntegerType())) \\\n",
    "             .withColumn(\"value\", col(\"value\").cast(DoubleType()))\n",
    "\n",
    "print(f\"BLS data: {bls_df.count()} rows\")\n",
    "\n",
    "print(bls_df.show(5, truncate=False))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLS data: 37182 rows\n",
      "+-----------+----+------+-----+--------------+\n",
      "|series_id  |year|period|value|footnote_codes|\n",
      "+-----------+----+------+-----+--------------+\n",
      "|PRS30006011|1995|Q01   |2.6  |null          |\n",
      "|PRS30006011|1995|Q02   |2.1  |null          |\n",
      "|PRS30006011|1995|Q03   |0.9  |null          |\n",
      "|PRS30006011|1995|Q04   |0.1  |null          |\n",
      "|PRS30006011|1995|Q05   |1.4  |null          |\n",
      "+-----------+----+------+-----+--------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T17:07:17.817941Z",
     "start_time": "2025-09-02T17:07:16.340740Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population data: 10 rows\n",
      "+---------+-------------+----+----------+\n",
      "|Nation ID|Nation       |Year|Population|\n",
      "+---------+-------------+----+----------+\n",
      "|01000US  |United States|2013|316128839 |\n",
      "|01000US  |United States|2014|318857056 |\n",
      "|01000US  |United States|2015|321418821 |\n",
      "|01000US  |United States|2016|323127515 |\n",
      "|01000US  |United States|2017|325719178 |\n",
      "|01000US  |United States|2018|327167439 |\n",
      "|01000US  |United States|2019|328239523 |\n",
      "|01000US  |United States|2021|331893745 |\n",
      "|01000US  |United States|2022|333287562 |\n",
      "|01000US  |United States|2023|334914896 |\n",
      "+---------+-------------+----+----------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load population data\n",
    "obj = s3_client.get_object(Bucket=BUCKET_NAME, Key='api-data/population_data.json')\n",
    "json_data = json.loads(obj['Body'].read().decode('utf-8'))\n",
    "\n",
    "# Extract data array\n",
    "if 'data' in json_data and 'data' in json_data['data']:\n",
    "    pop_data = json_data['data']['data']\n",
    "else:\n",
    "    pop_data = json_data.get('data', json_data)\n",
    "\n",
    "pop_df = spark.createDataFrame([Row(**row) for row in pop_data])\n",
    "pop_df = pop_df.withColumn(\"Year\", col(\"Year\").cast(IntegerType())) \\\n",
    "             .withColumn(\"Population\", col(\"Population\").cast(LongType()))\n",
    "\n",
    "print(f\"Population data: {pop_df.count()} rows\")\n",
    "print(pop_df.orderBy('Year').show(truncate=False))o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis 1: Population Statistics (2013-2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T16:57:16.004358Z",
     "start_time": "2025-09-02T16:57:15.752960Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Population: 322,069,808\n",
      "Std Deviation: 4,158,441\n"
     ]
    }
   ],
   "source": [
    "# Filter and calculate population stats\n",
    "pop_filtered = pop_df.filter((col(\"Year\") >= 2013) & (col(\"Year\") <= 2018))\n",
    "stats = pop_filtered.agg(\n",
    "    mean(\"Population\").alias(\"mean_pop\"),\n",
    "    stddev(\"Population\").alias(\"std_pop\")\n",
    ").collect()[0]\n",
    "\n",
    "print(f\"Mean Population: {stats.mean_pop:,.0f}\")\n",
    "print(f\"Std Deviation: {stats.std_pop:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis 2: Best Year per Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T17:01:56.678862Z",
     "start_time": "2025-09-02T17:01:54.857598Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total series analyzed: 282\n",
      "+-----------+----+------------------+\n",
      "|series_id  |year|value             |\n",
      "+-----------+----+------------------+\n",
      "|PRS30006011|2022|20.5              |\n",
      "|PRS30006012|2022|17.1              |\n",
      "|PRS30006013|1998|705.895           |\n",
      "|PRS30006021|2010|17.7              |\n",
      "|PRS30006022|2010|12.399999999999999|\n",
      "+-----------+----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter quarterly data and sum by series/year\n",
    "quarterly_df = bls_df.filter(col(\"period\").startswith(\"Q\"))\n",
    "\n",
    "yearly_sums = quarterly_df.groupBy(\"series_id\", \"year\") \\\n",
    "    .agg(sum(\"value\").alias(\"total_value\"))\n",
    "\n",
    "# Best year for each series\n",
    "from pyspark.sql.window import Window\n",
    "window = Window.partitionBy(\"series_id\").orderBy(desc(\"total_value\"))\n",
    "\n",
    "best_years = yearly_sums.withColumn(\"rank\", row_number().over(window)) \\\n",
    "    .filter(col(\"rank\") == 1) \\\n",
    "    .select(\"series_id\", \"year\", col(\"total_value\").alias(\"value\")) \\\n",
    "    .orderBy(\"series_id\")\n",
    "\n",
    "print(f\"Total series analyzed: {best_years.count()}\")\n",
    "best_years.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis 3: Combined Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T17:05:30.865919Z",
     "start_time": "2025-09-02T17:05:29.966604Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 31\n",
      "Records with population: 10\n",
      "+-----------+----+------+-----+----------+\n",
      "|series_id  |year|period|value|Population|\n",
      "+-----------+----+------+-----+----------+\n",
      "|PRS30006032|1995|Q01   |0.0  |null      |\n",
      "|PRS30006032|1996|Q01   |-4.2 |null      |\n",
      "|PRS30006032|1997|Q01   |2.8  |null      |\n",
      "|PRS30006032|1998|Q01   |0.9  |null      |\n",
      "|PRS30006032|1999|Q01   |-4.1 |null      |\n",
      "|PRS30006032|2000|Q01   |0.5  |null      |\n",
      "|PRS30006032|2001|Q01   |-6.3 |null      |\n",
      "|PRS30006032|2002|Q01   |-6.6 |null      |\n",
      "|PRS30006032|2003|Q01   |-5.7 |null      |\n",
      "|PRS30006032|2004|Q01   |2.0  |null      |\n",
      "+-----------+----+------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter specific series and join with population data\n",
    "filtered_bls = bls_df.filter(\n",
    "    (col(\"series_id\") == \"PRS30006032\") & \n",
    "    (col(\"period\") == \"Q01\")\n",
    ")\n",
    "\n",
    "combined = filtered_bls.join(\n",
    "    pop_df.select(col(\"year\").alias(\"pop_year\"), \"Population\"),\n",
    "    filtered_bls.year == col(\"pop_year\"),\n",
    "    \"left\"\n",
    ").select(\n",
    "    \"series_id\", \"year\", \"period\", \"value\", \"Population\"\n",
    ").orderBy(\"year\")\n",
    "\n",
    "total_records = combined.count()\n",
    "with_population = combined.filter(col(\"Population\").isNotNull()).count()\n",
    "\n",
    "print(f\"Total records: {total_records}\")\n",
    "print(f\"Records with population: {with_population}\")\n",
    "combined.show(10, truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
